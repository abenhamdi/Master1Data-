{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exercices Pratiques : Modèles de Machine Learning\n",
    "## Master 1 - Data Science & IA\n",
    "\n",
    "---\n",
    "\n",
    "**Durée estimée** : 2 heures minimum  \n",
    "**Niveau** : Autonome - SANS AIDE  \n",
    "**Dataset** : Global Air Pollution (Kaggle)\n",
    "\n",
    "---\n",
    "\n",
    "##  Objectifs\n",
    "\n",
    "Ce notebook vous permettra de maîtriser :\n",
    "1. **Préparation ML** (split, normalisation, validation)\n",
    "2. **Modèles de Classification** (10+ algorithmes)\n",
    "3. **Modèles de Régression** (8+ algorithmes)\n",
    "4. **Évaluation** (métriques, validation croisée)\n",
    "5. **Optimisation** (GridSearch, RandomSearch)\n",
    "6. **Ensemble Methods** (Voting, Stacking, Bagging, Boosting)\n",
    "\n",
    "---\n",
    "\n",
    "##  Règles du Jeu\n",
    "\n",
    "-  **PAS D'AIDE** : Pas de code fourni, vous devez chercher\n",
    "-  **Documentation** : Utilisez scikit-learn.org\n",
    "-  **Réflexion** : Comprenez chaque algorithme avant de l'utiliser\n",
    "-  **Validation** : Comparez les performances\n",
    "\n",
    "---\n",
    "\n",
    "**Bon courage ! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importer TOUTES les bibliothèques nécessaires\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO: Importer depuis sklearn :\n",
    "# - model_selection (train_test_split, cross_val_score, GridSearchCV, etc.)\n",
    "# - preprocessing (StandardScaler, LabelEncoder, etc.)\n",
    "# - metrics (accuracy_score, classification_report, confusion_matrix, etc.)\n",
    "# - Tous les modèles que vous allez utiliser\n",
    "\n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 1 : Préparation des Données pour ML (20 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1.1 : Chargement et Préparation Initiale\n",
    "\n",
    "**Objectif** : Préparer le dataset pour le Machine Learning.\n",
    "\n",
    "**Tâches** :\n",
    "1. Charger le dataset Global Air Pollution\n",
    "2. Afficher les informations de base (shape, colonnes, types)\n",
    "3. Gérer les valeurs manquantes :\n",
    "   - Supprimer les lignes avec plus de 50% de valeurs manquantes\n",
    "   - Imputer le reste avec la médiane (numériques) ou mode (catégorielles)\n",
    "4. Supprimer les doublons\n",
    "5. Afficher la shape finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1.2 : Création de la Variable Cible (Classification)\n",
    "\n",
    "**Objectif** : Créer une variable cible binaire pour la classification.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer une colonne 'Air_Quality_Binary' :\n",
    "   - 0 (Good Air) : AQI < 100\n",
    "   - 1 (Bad Air) : AQI >= 100\n",
    "2. Afficher la distribution de cette variable\n",
    "3. Vérifier l'équilibre des classes (% de chaque classe)\n",
    "4. Si déséquilibre > 70/30, noter qu'il faudra gérer ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1.3 : Sélection et Encodage des Features\n",
    "\n",
    "**Objectif** : Préparer les features pour les modèles.\n",
    "\n",
    "**Tâches** :\n",
    "1. Sélectionner les features numériques pertinentes :\n",
    "   - CO AQI Value, Ozone AQI Value, NO2 AQI Value, PM2.5 AQI Value\n",
    "   - Latitude, Longitude (optionnel)\n",
    "2. Encoder les variables catégorielles si vous voulez les utiliser :\n",
    "   - Country : Label Encoding ou One-Hot (attention à la dimension !)\n",
    "3. Créer X (features) et y (target)\n",
    "4. Afficher les shapes de X et y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1.4 : Split Train/Test et Normalisation\n",
    "\n",
    "**Objectif** : Diviser les données et normaliser.\n",
    "\n",
    "**Tâches** :\n",
    "1. Splitter X et y en train/test (70/30)\n",
    "   - Utiliser random_state=42\n",
    "   - Utiliser stratify=y pour préserver la distribution\n",
    "2. Normaliser les features avec StandardScaler :\n",
    "   - Fitter UNIQUEMENT sur X_train\n",
    "   - Transformer X_train et X_test\n",
    "3. Afficher les shapes de tous les ensembles\n",
    "4. Vérifier que la moyenne de X_train_scaled ≈ 0 et std ≈ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 2 : Modèles de Classification (40 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.1 : Baseline - Dummy Classifier\n",
    "\n",
    "**Objectif** : Créer un modèle de référence.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un DummyClassifier (strategy='most_frequent')\n",
    "2. Entraîner sur X_train_scaled, y_train\n",
    "3. Prédire sur X_test_scaled\n",
    "4. Calculer et afficher :\n",
    "   - Accuracy\n",
    "   - Classification report\n",
    "   - Confusion matrix\n",
    "5. Sauvegarder le score dans un dictionnaire pour comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.2 : Régression Logistique\n",
    "\n",
    "**Objectif** : Implémenter un modèle linéaire.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un LogisticRegression (random_state=42, max_iter=1000)\n",
    "2. Entraîner et prédire\n",
    "3. Calculer toutes les métriques :\n",
    "   - Accuracy, Precision, Recall, F1-Score\n",
    "   - ROC-AUC\n",
    "   - Confusion Matrix\n",
    "4. Tracer la courbe ROC\n",
    "5. Sauvegarder les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.3 : K-Nearest Neighbors (KNN)\n",
    "\n",
    "**Objectif** : Implémenter un modèle basé sur la distance.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester KNN avec différentes valeurs de k : [3, 5, 7, 10, 15]\n",
    "2. Pour chaque k :\n",
    "   - Entraîner le modèle\n",
    "   - Calculer l'accuracy sur train et test\n",
    "3. Tracer une courbe : k vs accuracy (train et test)\n",
    "4. Identifier le meilleur k\n",
    "5. Entraîner le modèle final avec le meilleur k\n",
    "6. Calculer toutes les métriques et sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.4 : Support Vector Machine (SVM)\n",
    "\n",
    "**Objectif** : Implémenter un SVM.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester SVM avec différents noyaux :\n",
    "   - 'linear'\n",
    "   - 'rbf'\n",
    "   - 'poly'\n",
    "2. Pour chaque noyau :\n",
    "   - Entraîner (attention : peut être lent !)\n",
    "   - Calculer accuracy\n",
    "3. Comparer les performances\n",
    "4. Garder le meilleur noyau\n",
    "5. Calculer toutes les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.5 : Decision Tree\n",
    "\n",
    "**Objectif** : Implémenter un arbre de décision.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un DecisionTreeClassifier (random_state=42)\n",
    "2. Entraîner et prédire\n",
    "3. Calculer les métriques\n",
    "4. Afficher l'importance des features (feature_importances_)\n",
    "5. Créer un barplot des feature importances\n",
    "6. Visualiser l'arbre (limité à 3 niveaux de profondeur)\n",
    "7. Comparer accuracy train vs test (overfitting ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.6 : Random Forest\n",
    "\n",
    "**Objectif** : Implémenter une forêt aléatoire.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un RandomForestClassifier :\n",
    "   - n_estimators=100\n",
    "   - random_state=42\n",
    "2. Entraîner et prédire\n",
    "3. Calculer toutes les métriques\n",
    "4. Afficher l'importance des features\n",
    "5. Comparer avec Decision Tree :\n",
    "   - Quelle amélioration ?\n",
    "   - Moins d'overfitting ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.7 : Gradient Boosting\n",
    "\n",
    "**Objectif** : Implémenter le boosting.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester 3 algorithmes de boosting :\n",
    "   - GradientBoostingClassifier\n",
    "   - AdaBoostClassifier\n",
    "   - XGBoost (si installé : xgboost.XGBClassifier)\n",
    "2. Pour chaque algorithme :\n",
    "   - Entraîner avec paramètres par défaut\n",
    "   - Calculer accuracy\n",
    "3. Comparer les 3 algorithmes\n",
    "4. Garder le meilleur et calculer toutes les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.8 : Naive Bayes\n",
    "\n",
    "**Objectif** : Implémenter un classificateur probabiliste.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester 2 variantes :\n",
    "   - GaussianNB\n",
    "   - MultinomialNB (attention : nécessite features >= 0)\n",
    "2. Entraîner et comparer\n",
    "3. Calculer les métriques du meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.9 : Neural Network (MLP)\n",
    "\n",
    "**Objectif** : Implémenter un réseau de neurones.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un MLPClassifier :\n",
    "   - hidden_layer_sizes=(100, 50)\n",
    "   - max_iter=500\n",
    "   - random_state=42\n",
    "2. Entraîner et prédire\n",
    "3. Calculer toutes les métriques\n",
    "4. Tracer la courbe de loss (loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2.10 : Comparaison de TOUS les Modèles\n",
    "\n",
    "**Objectif** : Créer un tableau comparatif.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un DataFrame avec TOUS les modèles testés\n",
    "2. Colonnes : Model, Accuracy, Precision, Recall, F1, ROC-AUC, Train Time\n",
    "3. Trier par accuracy décroissante\n",
    "4. Afficher le tableau\n",
    "5. Créer un barplot comparatif des accuracies\n",
    "6. Identifier le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 3 : Modèles de Régression (30 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.0 : Préparation pour la Régression\n",
    "\n",
    "**Objectif** : Préparer les données pour prédire l'AQI (régression).\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer une nouvelle target : y_reg = AQI Value (continue)\n",
    "2. Utiliser les mêmes features que pour la classification\n",
    "3. Splitter en train/test (même split que classification)\n",
    "4. Normaliser (réutiliser le même scaler ou en créer un nouveau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.1 : Linear Regression\n",
    "\n",
    "**Objectif** : Régression linéaire simple.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un LinearRegression()\n",
    "2. Entraîner et prédire\n",
    "3. Calculer les métriques de régression :\n",
    "   - R² Score\n",
    "   - Mean Absolute Error (MAE)\n",
    "   - Mean Squared Error (MSE)\n",
    "   - Root Mean Squared Error (RMSE)\n",
    "4. Tracer : y_true vs y_pred (scatterplot)\n",
    "5. Afficher les coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.2 : Ridge et Lasso Regression\n",
    "\n",
    "**Objectif** : Régression avec régularisation.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester Ridge avec différents alpha : [0.1, 1, 10, 100]\n",
    "2. Tester Lasso avec différents alpha : [0.1, 1, 10, 100]\n",
    "3. Pour chaque modèle, calculer R² score\n",
    "4. Comparer Ridge vs Lasso vs Linear\n",
    "5. Identifier le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.3 : Decision Tree Regressor\n",
    "\n",
    "**Objectif** : Arbre de décision pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un DecisionTreeRegressor (random_state=42)\n",
    "2. Entraîner et prédire\n",
    "3. Calculer toutes les métriques\n",
    "4. Afficher l'importance des features\n",
    "5. Comparer train vs test score (overfitting ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.4 : Random Forest Regressor\n",
    "\n",
    "**Objectif** : Forêt aléatoire pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un RandomForestRegressor (n_estimators=100, random_state=42)\n",
    "2. Entraîner et prédire\n",
    "3. Calculer toutes les métriques\n",
    "4. Comparer avec DecisionTreeRegressor\n",
    "5. Afficher l'importance des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.5 : Gradient Boosting Regressor\n",
    "\n",
    "**Objectif** : Boosting pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester :\n",
    "   - GradientBoostingRegressor\n",
    "   - XGBoost (si installé)\n",
    "2. Entraîner et calculer métriques\n",
    "3. Comparer avec Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.6 : Support Vector Regression (SVR)\n",
    "\n",
    "**Objectif** : SVM pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un SVR (kernel='rbf')\n",
    "2. Entraîner et prédire (peut être lent !)\n",
    "3. Calculer les métriques\n",
    "4. Comparer avec les autres modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.7 : K-Nearest Neighbors Regressor\n",
    "\n",
    "**Objectif** : KNN pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Tester avec k=[3, 5, 7, 10]\n",
    "2. Identifier le meilleur k\n",
    "3. Calculer les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.8 : Neural Network Regressor (MLP)\n",
    "\n",
    "**Objectif** : Réseau de neurones pour la régression.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un MLPRegressor\n",
    "2. Entraîner et prédire\n",
    "3. Calculer les métriques\n",
    "4. Tracer la courbe de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3.9 : Comparaison des Modèles de Régression\n",
    "\n",
    "**Objectif** : Tableau comparatif complet.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un DataFrame avec TOUS les modèles de régression\n",
    "2. Colonnes : Model, R², MAE, MSE, RMSE, Train Time\n",
    "3. Trier par R² décroissant\n",
    "4. Créer un barplot comparatif\n",
    "5. Identifier le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 4 : Optimisation des Hyperparamètres (20 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4.1 : GridSearchCV\n",
    "\n",
    "**Objectif** : Optimiser un modèle avec recherche exhaustive.\n",
    "\n",
    "**Tâches** :\n",
    "1. Choisir votre meilleur modèle de classification (ex: Random Forest)\n",
    "2. Définir une grille de paramètres :\n",
    "   ```python\n",
    "   param_grid = {\n",
    "       'n_estimators': [50, 100, 200],\n",
    "       'max_depth': [None, 10, 20],\n",
    "       'min_samples_split': [2, 5, 10]\n",
    "   }\n",
    "   ```\n",
    "3. Créer un GridSearchCV (cv=5)\n",
    "4. Entraîner (attention : peut être long !)\n",
    "5. Afficher les meilleurs paramètres\n",
    "6. Afficher le meilleur score\n",
    "7. Comparer avec le modèle non optimisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4.2 : RandomizedSearchCV\n",
    "\n",
    "**Objectif** : Optimiser avec recherche aléatoire (plus rapide).\n",
    "\n",
    "**Tâches** :\n",
    "1. Utiliser le même modèle\n",
    "2. Définir des distributions de paramètres\n",
    "3. Créer un RandomizedSearchCV (n_iter=20, cv=5)\n",
    "4. Entraîner\n",
    "5. Comparer avec GridSearchCV :\n",
    "   - Temps d'exécution\n",
    "   - Performance\n",
    "6. Quel est le meilleur compromis temps/performance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4.3 : Validation Croisée Complète\n",
    "\n",
    "**Objectif** : Évaluer la stabilité des modèles.\n",
    "\n",
    "**Tâches** :\n",
    "1. Pour vos 5 meilleurs modèles de classification :\n",
    "   - Appliquer cross_val_score avec cv=10\n",
    "   - Calculer mean et std des scores\n",
    "2. Créer un DataFrame avec les résultats\n",
    "3. Créer un boxplot des scores de validation croisée\n",
    "4. Quel modèle est le plus stable ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 5 : Ensemble Methods (20 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5.1 : Voting Classifier\n",
    "\n",
    "**Objectif** : Combiner plusieurs modèles.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un VotingClassifier avec vos 3 meilleurs modèles\n",
    "2. Tester 'hard' voting et 'soft' voting\n",
    "3. Entraîner et prédire\n",
    "4. Calculer les métriques\n",
    "5. Comparer avec les modèles individuels\n",
    "6. Le voting améliore-t-il les performances ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5.2 : Bagging Classifier\n",
    "\n",
    "**Objectif** : Bootstrap aggregating.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un BaggingClassifier :\n",
    "   - base_estimator : DecisionTreeClassifier\n",
    "   - n_estimators=50\n",
    "2. Entraîner et évaluer\n",
    "3. Comparer avec un seul DecisionTree\n",
    "4. Comparer avec Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5.3 : Stacking Classifier (Avancé)\n",
    "\n",
    "**Objectif** : Empiler plusieurs modèles.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un StackingClassifier :\n",
    "   - estimators : liste de (nom, modèle)\n",
    "   - final_estimator : LogisticRegression\n",
    "2. Utiliser au moins 3 modèles de base différents\n",
    "3. Entraîner et évaluer\n",
    "4. Comparer avec Voting et les modèles individuels\n",
    "5. Quel est le meilleur ensemble method ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  PARTIE 6 : Analyse Finale et Conclusions (10 min)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6.1 : Meilleur Modèle Global\n",
    "\n",
    "**Objectif** : Identifier le champion.\n",
    "\n",
    "**Tâches** :\n",
    "1. Créer un tableau récapitulatif de TOUS les modèles testés\n",
    "2. Identifier le meilleur modèle de classification\n",
    "3. Identifier le meilleur modèle de régression\n",
    "4. Pour chaque champion :\n",
    "   - Afficher toutes les métriques\n",
    "   - Afficher l'importance des features\n",
    "   - Créer des visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6.2 : Analyse des Erreurs\n",
    "\n",
    "**Objectif** : Comprendre où le modèle se trompe.\n",
    "\n",
    "**Tâches** :\n",
    "1. Pour le meilleur modèle de classification :\n",
    "   - Identifier les exemples mal classifiés\n",
    "   - Analyser leurs caractéristiques\n",
    "   - Y a-t-il des patterns ?\n",
    "2. Pour le meilleur modèle de régression :\n",
    "   - Calculer les résidus (erreurs)\n",
    "   - Tracer un histogramme des résidus\n",
    "   - Tracer résidus vs prédictions\n",
    "   - Les résidus sont-ils normalement distribués ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6.3 : Recommandations Finales\n",
    "\n",
    "**Objectif** : Synthétiser vos apprentissages.\n",
    "\n",
    "**Tâches** :\n",
    "1. Rédiger un court rapport (markdown) avec :\n",
    "   - Meilleur modèle de classification et pourquoi\n",
    "   - Meilleur modèle de régression et pourquoi\n",
    "   - Features les plus importantes\n",
    "   - Limites et améliorations possibles\n",
    "2. Si vous deviez déployer un modèle en production :\n",
    "   - Lequel choisiriez-vous ?\n",
    "   - Pourquoi ?\n",
    "   - Quels compromis (performance vs complexité vs temps) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  Félicitations !\n",
    "\n",
    "Vous avez terminé les exercices sur les modèles de Machine Learning !\n",
    "\n",
    "##  Modèles Maîtrisés\n",
    "\n",
    "### Classification (10+ modèles)\n",
    " Dummy Classifier (Baseline)  \n",
    " Logistic Regression  \n",
    " K-Nearest Neighbors  \n",
    " Support Vector Machine  \n",
    " Decision Tree  \n",
    " Random Forest  \n",
    " Gradient Boosting  \n",
    " AdaBoost  \n",
    " Naive Bayes  \n",
    " Neural Network (MLP)  \n",
    "\n",
    "### Régression (8+ modèles)\n",
    " Linear Regression  \n",
    " Ridge Regression  \n",
    " Lasso Regression  \n",
    " Decision Tree Regressor  \n",
    " Random Forest Regressor  \n",
    " Gradient Boosting Regressor  \n",
    " Support Vector Regression  \n",
    " K-Nearest Neighbors Regressor  \n",
    " Neural Network Regressor  \n",
    "\n",
    "### Ensemble Methods\n",
    " Voting Classifier  \n",
    " Bagging  \n",
    " Stacking  \n",
    "\n",
    "### Optimisation\n",
    " GridSearchCV  \n",
    " RandomizedSearchCV  \n",
    " Cross-Validation  \n",
    "\n",
    "##  Vous êtes maintenant prêt(e) pour :\n",
    "\n",
    "- Choisir le bon algorithme selon le problème\n",
    "- Évaluer et comparer des modèles\n",
    "- Optimiser les hyperparamètres\n",
    "- Déployer des modèles en production\n",
    "\n",
    "---\n",
    "\n",
    "**Bravo pour votre travail ! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}